## **Code Peer Review Templete**
------------------
- 코더 : 김동규
- 리뷰어 : 김경훈

## **PRT(PeerReviewTemplate)**
------------------  
- [x] **1. 코드가 정상적으로 동작하고 주어진 문제를 해결했나요?**

>|번호|평가문항|상세기준|평가결과|
>|:---:|---|---|:---:|
>|1|번역기 모델 학습에 필요한 텍스트 데이터 전처리가 한국어 포함하여 잘 이루어졌다.|구두점, 대소문자, 띄어쓰기, 한글 형태소분석 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.|⭐|
>|2|Attentional Seq2seq 모델이 정상적으로 구동된다.|seq2seq 모델 훈련 과정에서 training loss가 안정적으로 떨어지면서 학습이 진행됨이 확인되었다.|⭐|
>|3|테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.|테스트용 디코더 모델이 정상적으로 만들어져서, 정답과 어느 정도 유사한 영어 번역이 진행됨을 확인하였다.|⭐|

* 루브릭의 모든 사항을 만족하면서 정상적으로 동작하는 것 같습니다.
* 결과에 대한 시각화도 잘 되어 있습니다.
* `BahdanauAttention`뿐 아니라 `LuongAttention`로 실험도 되어 있습니다.

- [x] **2. 주석을 보고 작성자의 코드가 이해되었나요?**

* 네, 추가된 부분에 대해 친절하게 주석이 달려있고, 주석을 보고 코드가 이해 되었습니다.

- [x] **3. 코드가 에러를 유발할 가능성이 있나요?**

* 적절한 위치에 `assert`함수를 사용해서 에러를 예방하고 있습니다.

- [x] **4. 코드 작성자가 코드를 제대로 이해하고 작성했나요?**

* 네, 코드를 잘 이해하고 작성하였습니다.

- [x] **5. 코드가 간결한가요?**

* 네, 간결하게 작성 되었습니다.

## **참고링크 및 코드 개선 여부**

`train_step`에서 batch_accuracy를 `tf.equal`함수를 사용해서 측정하고 있는데, 이 방법이 NLP 모델의 평가 지표로 적합한 방법인지..?

[`BLEU Score`](https://keras.io/api/keras_nlp/metrics/bleu/)같은 지표를 사용해야 하지 않을까요?
    
